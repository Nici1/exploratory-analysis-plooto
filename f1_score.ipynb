{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn.metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import numpy as np\n",
    "from typing import Any, Dict, List, Tuple, Union\n",
    "\n",
    "from src.Kmeans import Kmeans\n",
    "from src.DBscan import DBscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(y_predicted, y_true):\n",
    "    confusion_matrix = sklearn.metrics.confusion_matrix(y_predicted, y_true)\n",
    "    precision = sklearn.metrics.precision_score(y_predicted, y_true)\n",
    "    recall = sklearn.metrics.recall_score(y_predicted, y_true)\n",
    "    f1 = sklearn.metrics.f1_score(y_predicted, y_true)\n",
    "\n",
    "    return [confusion_matrix, precision, recall, f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_Kmeans = {\n",
    "    \"n_clusters\": np.arange(1, 2),\n",
    "    \"treshold\": np.arange(1, 2),\n",
    "}\n",
    "\n",
    "param_grid_DBscan = {\n",
    "    \"eps\": np.arange(0.5, 1.5, 0.5),\n",
    "    \"treshold\": np.arange(0.5, 2, 0.5),\n",
    "    \"min_samples\": np.arange(1, 3, 1),\n",
    "}\n",
    "\n",
    "algorithms_params = [param_grid_Kmeans, param_grid_DBscan] \n",
    "algorithms = [\"Kmeans\", \"DBscan\"]\n",
    "\n",
    "metrics = np.empty([2, 9, 5], dtype=object)\n",
    "\n",
    "for i in range(1,9):\n",
    "\n",
    "    df_test = pd.read_csv(f\"data/sensor-cleaning-data/cleaned/test/data{i}.csv\")\n",
    "\n",
    "    df_original = pd.read_csv(f\"data/sensor-cleaning-data/cleaned/test/reformatted/data{i}.csv\")\n",
    "\n",
    "    for idx, row in df_original.iterrows():\n",
    "\n",
    "        if row[\"errorRate\"] == 0.0:\n",
    "            df_original[\"errorRate\"].iloc[idx] = 1\n",
    "        else:\n",
    "            df_original[\"errorRate\"].iloc[idx] = -1\n",
    "\n",
    "    df_original[\"errorRate\"] = df_original[\"errorRate\"].astype(int)\n",
    "\n",
    "    for alg_id, alg in enumerate(algorithms_params):\n",
    "        score = []\n",
    "        for params in itertools.product(*alg.values()):\n",
    "\n",
    "            inner_dict = {k: v for (k, v) in zip(algorithms_params[alg_id].keys(), params)}\n",
    "\n",
    "            conf = {\n",
    "                \"filtering\": \"None\",\n",
    "                \"train_data\": f\"data/sensor-cleaning-data/cleaned/train/data{i}.csv\",\n",
    "                \"input_vector_size\": 1,\n",
    "                \"warning_stages\": [0.7, 0.9],\n",
    "                **inner_dict,\n",
    "                \"output\": [\"FileOutput()\"],\n",
    "                \"output_conf\": [\n",
    "                    {\n",
    "                        \"file_path\": f\"{algorithms[alg_id]}/sensor-cleaning-data/data{i}.csv\",\n",
    "                        \"file_name\": f\"{algorithms[alg_id]}/sensor-cleaning-data/data{i}.csv\",\n",
    "                        \"mode\": \"w\",\n",
    "                    }\n",
    "                ],\n",
    "            }\n",
    "\n",
    "            class_name = algorithms[alg_id]\n",
    "\n",
    "            class_ = globals()[class_name]\n",
    "\n",
    "            detector = class_(conf)\n",
    "\n",
    "            mask = []\n",
    "            y_predicted = []\n",
    "\n",
    "            for idx, row in df_test.iterrows():\n",
    "\n",
    "                status_code = detector.message_insert(\n",
    "                        {\n",
    "                            \"timestamp\": df_test[\"timestamp\"].iloc[idx],\n",
    "                            \"ftr_vector\": [df_test[\"ftr_vector\"].iloc[idx]],\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "                if status_code == 2:\n",
    "                    mask.append(False)\n",
    "                if status_code == 1:\n",
    "                    mask.append(True)\n",
    "                    y_predicted.append(1)\n",
    "                elif status_code == -1:\n",
    "                    mask.append(True)\n",
    "                    y_predicted.append(-1)\n",
    "\n",
    "            df_original = df_original[mask]\n",
    "            y_true = list(df_original[\"errorRate\"])\n",
    "\n",
    "            m = compute_metrics(y_predicted, y_true)\n",
    "            m.append(params)\n",
    "            score.append(m)\n",
    "\n",
    "            # print(score)\n",
    "\n",
    "        max_list = max(score, key=lambda x: x[3])\n",
    "      \n",
    "        metrics[alg_id, i-1, :] = max_list\n",
    "\n",
    "        print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, TransformerMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.metrics import euclidean_distances\n",
    "\n",
    "\n",
    "class TemplateEstimator(BaseEstimator):\n",
    "    \"\"\"A template estimator to be used as a reference implementation.\n",
    "\n",
    "    For more information regarding how to build your own estimator, read more\n",
    "    in the :ref:`User Guide <user_guide>`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    demo_param : str, default='demo_param'\n",
    "        A parameter used for demonstation of how to pass and store paramters.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from skltemplate import TemplateEstimator\n",
    "    >>> import numpy as np\n",
    "    >>> X = np.arange(100).reshape(100, 1)\n",
    "    >>> y = np.zeros((100, ))\n",
    "    >>> estimator = TemplateEstimator()\n",
    "    >>> estimator.fit(X, y)\n",
    "    TemplateEstimator()\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, demo_param=None):\n",
    "        self.demo_param = demo_param\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"A reference implementation of a fitting function.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
    "            The training input samples.\n",
    "        y : array-like, shape (n_samples,) or (n_samples, n_outputs)\n",
    "            The target values (class labels in classification, real numbers in\n",
    "            regression).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "            Returns self.\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        inner_dict = self.demo_param[\"param_grid_Kmeans\"]\n",
    "\n",
    "        conf = {\n",
    "            \"filtering\": \"None\",\n",
    "            \"train_data\": \"data/sensor-cleaning-data/cleaned/train/data1.csv\",\n",
    "            \"input_vector_size\": 1,\n",
    "            \"warning_stages\": [0.7, 0.9],\n",
    "            **inner_dict,\n",
    "            \"output\": [\"FileOutput()\"],\n",
    "            \"output_conf\": [\n",
    "                {\n",
    "                    \"file_path\": f\"Kmeans/sensor-cleaning-data/data{i}.csv\",\n",
    "                    \"file_name\": f\"Kmeans/sensor-cleaning-data/data{i}.csv\",\n",
    "                    \"mode\": \"w\",\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "\n",
    "       \n",
    "\n",
    "        self.detector_ = Kmeans(conf)\n",
    "        \n",
    "        X, y = check_X_y(X, y, accept_sparse=True)\n",
    "        self.is_fitted_ = True\n",
    "        # `fit` should always return `self`\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"A reference implementation of a predicting function.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
    "            The training input samples.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        y : ndarray, shape (n_samples,)\n",
    "            Returns an array of ones.\n",
    "        \"\"\"\n",
    "\n",
    "        df_test = pd.read_csv(f\"data/sensor-cleaning-data/cleaned/test/data1.csv\")\n",
    "\n",
    "        mask = []\n",
    "        y_predicted = []\n",
    "\n",
    "        for idx, row in df_test.iterrows():\n",
    "\n",
    "            status_code = self.detector_.message_insert(\n",
    "                    {\n",
    "                        \"timestamp\": df_test[\"timestamp\"].iloc[idx],\n",
    "                        \"ftr_vector\": [df_test[\"ftr_vector\"].iloc[idx]],\n",
    "                    }\n",
    "                )\n",
    "\n",
    "            if status_code == 2:\n",
    "                mask.append(False)\n",
    "            if status_code == 1:\n",
    "                mask.append(True)\n",
    "                y_predicted.append(1)\n",
    "            elif status_code == -1:\n",
    "                mask.append(True)\n",
    "                y_predicted.append(-1)\n",
    "\n",
    "        y_true = list(df_original[\"errorRate\"])\n",
    "        y_true = np.array(y_true).reshape(-1, 1)\n",
    "\n",
    "        X = check_array(X, accept_sparse=True)\n",
    "        check_is_fitted(self, \"is_fitted_\")\n",
    "        # return np.empty(X.shape[0], dtype=np.int64)\n",
    "        return m\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_Kmeans = {\n",
    "    \"n_clusters\": 2,\n",
    "    \"treshold\": 2,\n",
    "}\n",
    "\n",
    "df_test = pd.read_csv(f\"data/sensor-cleaning-data/cleaned/test/data1.csv\")\n",
    "\n",
    "df_original = pd.read_csv(f\"data/sensor-cleaning-data/cleaned/test/reformatted/data1.csv\")\n",
    "\n",
    "for idx, row in df_original.iterrows():\n",
    "\n",
    "    if row[\"errorRate\"] == 0.0:\n",
    "        df_original[\"errorRate\"].iloc[idx] = 1\n",
    "    else:\n",
    "        df_original[\"errorRate\"].iloc[idx] = -1\n",
    "\n",
    "df_original[\"errorRate\"] = df_original[\"errorRate\"].astype(int)\n",
    "\n",
    "\n",
    "df_train = pd.read_csv(\"data/sensor-cleaning-data/cleaned/train/data1.csv\")\n",
    "X = np.array(df_train['ftr_vector']).reshape(-1, 1)\n",
    "\n",
    "\n",
    "params = {\n",
    "    \"trainning_data\": \"data/sensor-cleaning-data/cleaned/train/data1.csv\",\n",
    "    \"testing_data\": \"data/sensor-cleaning-data/cleaned/test/data1.csv\",\n",
    "    \"original_data\": \"data/sensor-cleaning-data/cleaned/test/reformatted/data1.csv\",\n",
    "    \"param_grid_Kmeans\": param_grid_Kmeans,\n",
    "}\n",
    "\n",
    "temp = TemplateEstimator(demo_param=params)\n",
    "\n",
    "y = X\n",
    "temp.fit(X,y)\n",
    "temp.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid_Kmeans = {\n",
    "    \"n_clusters\": np.arange(1,4,1),\n",
    "    \"treshold\": np.arange(1,4,1),\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(TemplateEstimator(demo_param=params), param_grid_Kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.estimator_checks import check_estimator\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "params = {\n",
    "    \"trainning_data\": \"data/sensor-cleaning-data/cleaned/train/data1.csv\",\n",
    "    \"testing_data\": \"data/sensor-cleaning-data/cleaned/test/data1.csv\",\n",
    "    \"original_data\": \"data/sensor-cleaning-data/cleaned/test/reformatted/data1.csv\",\n",
    "    \"param_grid_Kmeans\" : param_grid_Kmeans\n",
    "}\n",
    "\n",
    "\n",
    "check_estimator(TemplateEstimator(demo_param=params))  # passes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.arange(100).reshape(100, 1)\n",
    "y = np.zeros((100,))\n",
    "estimator = TemplateEstimator()\n",
    "estimator.fit(X, y)\n",
    "plt.plot(estimator.predict(X))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal parameters: {'C': 1, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "parameters = {\"kernel\": (\"linear\", \"rbf\"), \"C\": [1, 10]}\n",
    "svc = svm.SVC()\n",
    "clf = GridSearchCV(svc, parameters)\n",
    "clf.fit(iris.data, iris.target)\n",
    "sorted(clf.cv_results_.keys())\n",
    "\n",
    "# Get the optimal parameters\n",
    "optimal_params = clf.best_params_\n",
    "\n",
    "print(\"Optimal parameters:\", optimal_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "a_det2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
